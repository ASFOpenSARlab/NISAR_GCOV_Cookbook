{"version":"1","records":[{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"ALERT: This Jupyter Book is under active development and currently uses pre-launch test data"},"type":"lvl2","url":"/#alert-this-jupyter-book-is-under-active-development-and-currently-uses-pre-launch-test-data","position":2},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"ALERT: This Jupyter Book is under active development and currently uses pre-launch test data"},"content":"\n\n\n\n\n\n\n\nSee the \n\nCookbook Contributor’s Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!\n\nNISAR GCOV, is a primary data product from the NISAR mission. GCOV, or Geocoded Coverage, provides calibrated, L-band radar data on a standardized grid, making it straightforward to load, analyze and explore in Python.\n\nAfter learning to access and visualize GCOV data in this cookbook, you will be ready to begin applying NISAR imagery to a wide range of Earth science applications, including ecosystem monitoring, hydrology, cryosphere studies, natural hazards, and surface change analysis.","type":"content","url":"/#alert-this-jupyter-book-is-under-active-development-and-currently-uses-pre-launch-test-data","position":3},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":4},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Motivation"},"content":"The NISAR mission will provide one of the most comprehensive global radar datasets ever collected, offering new opportunities to study the dynamic Earth. This cookbook is designed to help a wide range of users, including students, researchers, and communities, to begin working with NISAR’s GCOV products.\n\nBy introducing clear, hands-on examples, we hope to make the mission’s powerful data resources simple, approachable and usable. Our goal is to help you build the skills needed to explore GCOV data with confidence and apply NISAR’s capabilities to your own scientific, environmental, or community-focused questions.","type":"content","url":"/#motivation","position":5},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":6},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Authors"},"content":"Lewandowski, Alex. White, Julia. (Several others will be added as we produce notebooks)","type":"content","url":"/#authors","position":7},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Structure"},"content":"","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 1: Accessing NISAR GCOV Products","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-accessing-nisar-gcov-products","position":10},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 1: Accessing NISAR GCOV Products","lvl2":"Structure"},"content":"Learn where GCOV files come from, how to download them, and how to open them in Python.","type":"content","url":"/#section-1-accessing-nisar-gcov-products","position":11},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 2: Understanding GCOV Contents","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-understanding-gcov-contents","position":12},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 2: Understanding GCOV Contents","lvl2":"Structure"},"content":"Explore the structure of GCOV files and the meaning of key layers.","type":"content","url":"/#section-2-understanding-gcov-contents","position":13},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 3: Visualizing GCOV Data","lvl2":"Structure"},"type":"lvl3","url":"/#section-3-visualizing-gcov-data","position":14},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 3: Visualizing GCOV Data","lvl2":"Structure"},"content":"Create basic plots and maps using NISAR GCOV data.","type":"content","url":"/#section-3-visualizing-gcov-data","position":15},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 4: Building Simple Analyses","lvl2":"Structure"},"type":"lvl3","url":"/#section-4-building-simple-analyses","position":16},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Section 4: Building Simple Analyses","lvl2":"Structure"},"content":"Apply GCOV data to introductory examples from ecosystems, hydrology, hazards, and the cryosphere.","type":"content","url":"/#section-4-building-simple-analyses","position":17},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":18},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":19},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":20},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":21},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":22},{"hierarchy":{"lvl1":"Getting Started with the NISAR GCOV Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace “cookbook-example” with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":23},{"hierarchy":{"lvl1":"NISAR Level 2 Geocoded Covariance (GCOV) Product"},"type":"lvl1","url":"/notebooks/gcov-intro","position":0},{"hierarchy":{"lvl1":"NISAR Level 2 Geocoded Covariance (GCOV) Product"},"content":"","type":"content","url":"/notebooks/gcov-intro","position":1},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods"},"type":"lvl1","url":"/notebooks/nisar-gcov-sarchangedetectionmethods","position":0},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods"},"content":"","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods","position":1},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods"},"type":"lvl1","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#an-introduction-to-simple-sar-change-detection-methods","position":2},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods"},"content":"","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#an-introduction-to-simple-sar-change-detection-methods","position":3},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"Franz J Meyer; University of Alaska Fairbanks"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#franz-j-meyer-university-of-alaska-fairbanks","position":4},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"Franz J Meyer; University of Alaska Fairbanks"},"content":"\n\nThis notebook introduces you to a some popular change detection methods that can be applied on SAR time series data. SAR is an excellent tool for change detection. As SAR sensors are weather and illumination independent, and as SAR’s carry their own illumination source (active sensor), differences between repeated images are a direct indication of changes on the surface. This fact is exploited by the change detection methods introduced below.\n\nThe exercise is done in the framework of Jupyter Notebooks. The Jupyter Notebook environment is easy to launch in any web browser for interactive data exploration with provided or new training data. Notebooks are comprised of text written in a combination of executable python code and markdown formatting including latex style mathematical equations. Another advantage of Jupyter Notebooks is that they can easily be expanded, changed, and shared with new data sets or newly available time series steps. Therefore, they provide an excellent basis for collaborative and repeatable data analysis.\n\nThis notebook covers the following data analysis concepts:\n\nTime series metrics  95^{th} and 5^{th} percentile difference thresholding\n\nTime series coefficient of variation thresholding\n\nLog Ratio-based change detection from image pairs\n\n\n\n0. Importing Relevant Python Packages\n\nIn this notebook we will use the following scientific libraries:\n\nPandas is a Python library that provides high-level data structures and a vast variety of tools for analysis. The great feature of this package is the ability to translate rather complex operations with data into one or two commands. Pandas contains many built-in methods for filtering and combining data, as well as the time-series functionality.\n\nGDAL is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n\nNumPy is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects.\n\nMatplotlib is a low-level library for creating two-dimensional diagrams and graphs. With its help, you can build diverse charts, from histograms and scatterplots to non-Cartesian coordinates graphs. Moreover, many popular plotting libraries are designed to work in conjunction with matplotlib.\n\nThe asf-hyp3 API provides useful functions and scripts for accessing and processing SAR data via the Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline, or HyP3 (pronounced \"hype\").\n\nSciPY is a library that provides functions for numerical integration, interpolation, optimization, linear algebra and statistics.\n\nOur first step is to import them:\n\n# %%capture\n# from pathlib import Path\n# from os import system\n# import datetime # for date\n# import re\n\n# import pandas as pd # for DatetimeIndex\n# from osgeo import gdal # for Info\n# gdal.UseExceptions()\n\n# %matplotlib inline\n# import matplotlib.pyplot as plt\n# from matplotlib import animation\n# from matplotlib import rc\n# import numpy as np\n\n# from ipyfilechooser import FileChooser\n\n# from IPython.display import HTML\n\n# import opensarlab_lib as asfn\n# asfn.jupytertheme_matplotlib_format()\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#franz-j-meyer-university-of-alaska-fairbanks","position":5},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"1. Load Data Stack"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-1-load-data-stack","position":6},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"1. Load Data Stack"},"content":"In the Exercise4A-SARChangeDetectionMethods.ipynb notebook will used a dense 12-day repeat Sentinel-1 C-band SAR data stack. It contained imagery acquired during the year 2018 in Guatemala. The data was already prepared for you. Now, you will later learn how to download and pre-process Sentinel-1 images using the services of the \n\nAlaska Satellite Facility.\n\nBegin by writing a function to retrieve the absolute paths to each of our tiffs:\n\n# def get_tiff_paths(paths):\n#     tiff_paths = !ls $paths | sort -t_ -k5,5\n#     return tiff_paths\n\nSelect the directory holding your tiffs\n\nClick the Select button\n\nNavigate to your data directory\n\nClick the Select button\n\nConfirm that the desired path appears in green text\n\nClick the Change button to alter your selection\n\n# fc = FileChooser(Path.cwd())\n# display(fc)\n\nDetermine the path to the analysis directory containing the tiff directory:\n\nfrom pathlib import Path\n\nchange_detection_example_dir = Path.cwd() / \"change_detection_example\"\n\ndata_dir = change_detection_example_dir / \"data\"\ndata_dir.mkdir(parents=True, exist_ok=True)\n\nplot_dir = change_detection_example_dir / \"plots\"\nplot_dir.mkdir(exist_ok=True)\n\nimport os\nimport asf_search as asf\n# from getpass import getpass\n\n\nwkt = \"POLYGON((-57.759 -3.5099,-56.459 -3.5099,-56.459 -2.6352,-57.759 -2.6352,-57.759 -3.5099))\"\n\nopts=asf.ASFSearchOptions(**{\n    \"maxResults\": 250,\n    \"intersectsWith\": wkt,\n    \"processingLevel\": [\n        \"GCOV\"\n    ],\n    \"dataset\": [\n        \"NISAR\"\n    ],\n    \"productionConfiguration\": [\n        \"PR\"\n    ],\n    \"host\": \"cmr.uat.earthdata.nasa.gov\"\n})\n\nsession = asf.ASFSession(cmr_host='cmr.uat.earthdata.nasa.gov')\n# session.auth_with_token(getpass('UAT EDL token'))\nsession.auth_with_token(os.environ[\"UAT_TOKEN\"])\n\nresponse = asf.search(opts=opts)\n\nhdf5_files = response.find_urls(extension='.h5', pattern=r'^(?!.*STATS).*DHDH.*', directAccess=False)\nasf.download_urls(hdf5_files, data_dir, session=session, processes=4)\n\n# TODO: Delete when we have real NISAR data\n# Duplicates the one sample GCOV file we have\nimport shutil\n\nf = list(data_dir.glob('*.h5'))[0]\nfor i in range(7): \n    shutil.copy(f, f.parent / f\"{f.stem}_{i}.h5\")\n\ngcov_files = sorted(list(data_dir.glob(\"*.h5\")))\ngcov_files\n\nimport re\nimport h5py\nimport numpy as np\nimport xarray as xr\nimport dask.array as da\nfrom dask import delayed\n\n_date_regex = re.compile(r\"_(\\d{8}T\\d{6})_\")\ndef _get_ts(filename):\n    match = _date_regex.search(filename)\n    if match:\n        ts_str = match.group(1)\n        return np.datetime64(f\"{ts_str[:4]}-{ts_str[4:6]}-{ts_str[6:8]}T{ts_str[9:11]}:{ts_str[11:13]}:{ts_str[13:15]}\") \n    return np.datetime64(\"NaT\")\n\ndef open_gcov(gcov_paths, vars_to_load=(\"HHHH\", \"HVHV\", \"mask\", \"numberOfLooks\", \"rtcGammaToSigmaFactor\"), freqs=(\"A\",\"B\"), max_xy_chunk=2048):\n    gcov_paths = sorted(gcov_paths)\n    group = {f: f\"/science/LSAR/GCOV/grids/frequency{f}\" for f in freqs}\n    with h5py.File(gcov_paths[0], \"r\") as f0:\n        g = f0[group[freqs[0]]]\n        x, y = g[\"xCoordinates\"][...], g[\"yCoordinates\"][...]\n        proj = g[\"projection\"][()]\n    ny, nx = len(y), len(x)\n    time = np.array([_get_ts(p.name) for p in gcov_paths])\n    chunks = (1, 1, min(ny, max_xy_chunk), min(nx, max_xy_chunk))  # (time, frequency, y, x)\n\n    data_vars = {}\n    for v in vars_to_load:\n        per_freq = []\n        for freq in freqs:\n            with h5py.File(gcov_paths[0], \"r\") as f0:\n                dt = f0[f\"{group[freq]}/{v}\"].dtype\n            planes = [da.from_delayed(delayed(lambda p, d: h5py.File(p,\"r\")[d][...])(p, f\"{group[freq]}/{v}\"),\n                                      shape=(ny, nx), dtype=dt)[None, None, ...]\n                      for p in gcov_paths]\n            per_freq.append(da.concatenate(planes, axis=0))\n        stacked = da.concatenate(per_freq, axis=1).rechunk(chunks)\n        data_vars[v] = ((\"time\",\"frequency\",\"y\",\"x\"), stacked)\n\n    return xr.Dataset(\n        data_vars=data_vars,\n        coords={\"time\": time, \"frequency\": np.array(list(freqs)), \"y\": y, \"x\": x},\n        attrs={\"source\": \"NISAR L2 GCOV\", \"projection\": proj},\n    )\n\nds = open_gcov(gcov_files)\nds\n\n# TODO: remove this when there is real NISAR data\n# Fakes a time series by updating dates and backscatter\n\nimport pandas as pd\n\nfake_times = pd.date_range(\n    start=\"2025-11-02T22:06:39\",\n    periods=ds.sizes[\"time\"],\n    freq=\"D\"\n)\n\nds = ds.assign_coords(time=fake_times)\n\n# adjust each duplicated time step's backscatter values for better test visualization\nfactors = 1 + 0.3 * np.sin(np.linspace(0, 2*np.pi, ds.sizes[\"time\"]))\nscaled = ds * xr.DataArray(factors, dims=[\"time\"])\nscaled = scaled.assign_attrs(ds.attrs)\nds = scaled\nds\n\nDetermine the path to the analysis directory containing the tiff directory:\n\n# polarization = asfn.select_parameter(['VV', 'VH'], 'polarization:')\n# polarization\n\n%%time\npolarization = \"HVHV\"\nfrequency = \"A\"\n\nda = ds[polarization].sel(frequency=frequency,\n                          x=slice(400000.0, 500000.0),\n                          y=slice(9700000.0, 9600000.0))\nda = da.assign_attrs({**ds.attrs, **da.attrs})\n# da.load()\nda\n\n# pol = polarization.value\n# print(f'polarization: {pol}')\n\nCreate a wildcard path to the tiffs:\n\n# if pol == 'VV':\n#     wildcard_path = f\"{tiff_dir}/*VV*.tif*\"\n# else:\n#     wildcard_path = f\"{tiff_dir}/*VH*.tif*\"\n# print(f'wildcard_path: \\n{wildcard_path}')\n\nWrite a function to extract the tiff dates from a wildcard path.\n\n# def get_date(pth):\n#     date_regex = r'(?<=_)\\d{8}(?=T\\d{6})'\n#     try:\n#         return re.search(date_regex, str(pth)).group(0)\n#     except AttributeError:\n#         raise Exception(f\"Date string not found in {pth}\")\n\nCall get_dates() to collect the product acquisition dates:\n\n# file_ext = None\n# if pol == 'VV':\n#     file_ext = f'*VV*.tif*'\n# else:\n#     file_ext = f'*VH*.tif*'\n\n# dates = sorted([get_date(d) for d in tiff_dir.rglob(file_ext)])\n# print(f'dates: \\n{dates}')\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-1-load-data-stack","position":7},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"2. Create the VRTs"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-2-create-the-vrts","position":8},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"2. Create the VRTs"},"content":"Create the virtual raster table for the GeoTiffs:\n\n# raster_path = f\"{analysis_dir}/raster_stack_{pol}.vrt\"\n# !gdalbuildvrt -separate $raster_path $wildcard_path\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-2-create-the-vrts","position":9},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"3. Define Some Python Helper Functions for this Notebook"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-3-define-some-python-helper-functions-for-this-notebook","position":10},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"3. Define Some Python Helper Functions for this Notebook"},"content":"We are defining two helper functions for this notebook:\n\nCreateGeoTiff() to write out images\n\ntimeseries_metrics() to compute various metrics from a time series data stack\n\ndef create_geotiff(name, array, data_type, ndv, bandnames=None, \n                   ref_image=None, geo_t=None, projection=None):\n    # If it's a 2D image we fake a third dimension:\n    if len(array.shape) == 2:\n        array = np.array([array])\n    if ref_image == None and (geo_t == None or projection == None):\n        raise RuntimeWarning('ref_image or settings required.')\n    if bandnames != None:\n        if len(bandnames) != array.shape[0]:\n            raise RuntimeError(f'Need {Array.shape[0]} bandnames. {len(bandnames)} given')\n    else:\n        bandnames = [f'Band {i+1}' for i in range(array.shape[0])]\n    if ref_image != None:\n        refimg = gdal.Open(ref_image)\n        geo_t = refimg.GetGeoTransform()\n        Projection = refimg.GetProjection()\n    driver = gdal.GetDriverByName('GTIFF')\n    array[np.isnan(array)] = ndv\n    dataset = driver.Create(name, array.shape[2], array.shape[1], \n                            array.shape[0], data_type)\n    dataset.SetGeoTransform(geo_t)\n    dataset.SetProjection(projection)\n    for i, image in enumerate(array, 1):\n        dataset.GetRasterBand(i).WriteArray(image)\n        dataset.GetRasterBand(i).SetNoDataValue(ndv)\n        dataset.SetDescription(bandnames[i-1])\n    dataset.FlushCache()\n    return name\n\nda\n\n# def timeseries_metrics(raster, ndv=np.nan):     \n#     # Make us of numpy nan functions\n#     # Check if type is a float array\n#     if not raster.dtype.name.find('float')>-1:\n#         raster = raster.astype(np.float64)\n#     # Set ndv to nan\n#     if not np.isnan(ndv):\n#         raster[np.equal(raster,ndv)] = np.nan\n#     # Build dictionary of the metrics\n#     tsmetrics={}\n#     rperc = np.nanpercentile(raster,[5,50,95], axis=0)\n#     tsmetrics['mean'] = np.nanmean(raster, axis=0)\n#     tsmetrics['max'] = np.nanmax(raster, axis=0)\n#     tsmetrics['min'] = np.nanmin(raster, axis=0)\n#     tsmetrics['range'] = tsmetrics['max'] - tsmetrics['min']\n#     tsmetrics['median'] = rperc[1]\n#     tsmetrics['p5'] = rperc[0]\n#     tsmetrics['p95'] = rperc[2]\n#     tsmetrics['prange'] = rperc[2]-rperc[0]\n    # tsmetrics['var'] = np.nanvar(raster, axis=0)\n    # tsmetrics['std'] = np.sqrt(tsmetrics['var'])\n    # tsmetrics['CV'] = np.abs(tsmetrics['var'] / tsmetrics['mean'])\n#     return tsmetrics\n\ndef timeseries_metrics(da):     \n    q = da.quantile([0.05, 0.5, 0.95], dim=\"time\")\n    p05 = q.sel(quantile=0.05, drop=True)\n    p50 = q.sel(quantile=0.50, drop=True)\n    p95 = q.sel(quantile=0.95, drop=True)\n    prange = p95 - p05\n    \n    max = da.max(dim=\"time\")\n    min = da.min(dim=\"time\")\n    range = max - min\n\n    mean = da.mean(dim=\"time\")\n    var = da.var(dim=\"time\")\n    std = da.std(dim=\"time\")\n    cv = std / xr.where(mean != 0, mean, np.nan)\n    \n    return xr.Dataset(\n        dict(\n            min=min, max=max, range=range,\n            mean=mean, var=var, std=std, CV=cv,\n            p05=p05, p50=p50, p95=p95,\n            prange=p95 - p05\n        )\n    )\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-3-define-some-python-helper-functions-for-this-notebook","position":11},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4. Create a Pandas Time Index and Display the VRT Band Dates"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-create-a-pandas-time-index-and-display-the-vrt-band-dates","position":12},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4. Create a Pandas Time Index and Display the VRT Band Dates"},"content":"Create an index of timedelta64 data with Pandas:\n\n# tindex = pd.DatetimeIndex(dates)\n\nPrint the bands and dates for all images in the virtual raster table (VRT):\n\n# j = 1\n# print(f\"Bands and dates for {raster_path}\")\n# for i in tindex:\n#     print(\"{:4d} {}\".format(j, i.date()), end=' ')\n#     j += 1\n#     if j%5 == 1:\n#         print()\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-create-a-pandas-time-index-and-display-the-vrt-band-dates","position":13},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4. Create a Time Series Animation to get an Idea of the Dynamics at the Site"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-create-a-time-series-animation-to-get-an-idea-of-the-dynamics-at-the-site","position":14},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4. Create a Time Series Animation to get an Idea of the Dynamics at the Site"},"content":"","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-create-a-time-series-animation-to-get-an-idea-of-the-dynamics-at-the-site","position":15},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"4.1 Load Time Series Stack","lvl2":"4. Create a Time Series Animation to get an Idea of the Dynamics at the Site"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-1-load-time-series-stack","position":16},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"4.1 Load Time Series Stack","lvl2":"4. Create a Time Series Animation to get an Idea of the Dynamics at the Site"},"content":"Now we are ready to create a time series animation from the calibrated SAR data.\n\nFirst, create a raster from band 0 and a raster stack from all the images:\n\n# img = gdal.Open(raster_path)\n# band = img.GetRasterBand(1)\n# raster0 = band.ReadAsArray()\n# band_number = 0 # Needed for updates\n# rasterstack = img.ReadAsArray()\n\nPrint the bands, pixels, and lines:\n\n# print(f\"Number of  bands: {img.RasterCount}\")\n# print(f\"Number of pixels: {img.RasterXSize}\")\n# print(f\"Number of  lines: {img.RasterYSize}\")\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-1-load-time-series-stack","position":17},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4.2 Data Conversion between dB and Power Scales"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-2-data-conversion-between-db-and-power-scales","position":18},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4.2 Data Conversion between dB and Power Scales"},"content":"The data at hand are radiometrically terrain corrected images, which are often expressed as terrain flattened \\gamma^0 backscattering coefficients. For forest and land cover monitoring applications \\gamma^0 is the preferred metric.\n\nTo use a logarithmic scale instead of the natural power scale, you can set the following variable to True:\n\n# todB = True\n\n# labeldB = 'dB' if todB else 'linear'\n\n# def convert(raster, todB=todB):\n#     if todB:\n#         return 10 * np.ma.log10(raster)\n#     else:\n#         return raster\n\n%%time\nda_db = 10*np.log10(da)\nda_db\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-2-data-conversion-between-db-and-power-scales","position":19},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4.3 Create Time Series Animation"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-3-create-time-series-animation","position":20},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"4.3 Create Time Series Animation"},"content":"Create and move into a directory in which to store our plots and animations:\n\n# product_path = analysis_dir/f'plots_and_animations'\n\n# if not product_path.exists():\n#     print(f'{product_path} created')\n#     product_path.mkdir()\n\nNow we can create the information needed to animate our data:\n\n%%time\nfrom matplotlib import pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.animation import FFMpegWriter, PillowWriter\n\nvmin, vmax = (da_db.quantile([0.05, 0.95], skipna=True).values.astype(float))\n\nfig, ax = plt.subplots(figsize=(6, 6))\nframe_0 = da_db.isel(time=0).values\nim = ax.imshow(frame_0, vmin=vmin, vmax=vmax, origin=\"upper\", cmap=\"grey\")\ncb = fig.colorbar(im, ax=ax, label=\"γ⁰ (dB)\")\nax.set_title(np.datetime_as_string(da_db.time.values[0], unit='s'))\nax.set_axis_off()\n\ndef animate(i):\n    frame = da_db.isel(time=i).values\n    im.set_data(frame)\n    ax.set_title(np.datetime_as_string(da_db.time.values[i], unit='s'))\n    return (im,)\n\nani = FuncAnimation(fig, animate, frames=da_db.sizes[\"time\"], interval=300, blit=False)\n\nplt.show()\n\nfrom IPython.display import HTML\n\nHTML(ani.to_jshtml())\n\n# %%capture \n# fig = plt.figure(figsize=(10, 5))\n# ax = fig.subplots()\n# ax.axis('off')\n\n# copyRaster = np.copy(convert(rasterstack))\n# vmin = np.nanpercentile(copyRaster, 1)\n# vmax = np.nanpercentile(copyRaster, 99)\n\n# im = ax.imshow(convert(raster0), cmap='inferno', vmin=vmin, vmax=vmax)\n# cbar = fig.colorbar(im)\n# cbar.set_label(labeldB)\n# ax.set_title(\"{}\".format(tindex[0].date()))\n# plt.rcParams.update({'font.size': 14})\n\n# def animate(i):\n#     ax.set_title(\"{}\".format(tindex[i].date()))\n#     im.set_data(convert(rasterstack[i]))\n\n# # Interval is given in milliseconds\n# ani = animation.FuncAnimation(fig, animate, frames=rasterstack.shape[0], interval=300)\n\nConfigure matplotlib’s RC settings for the animation:\n\n# rc('animation', embed_limit=40971520.0)  # We need to increase the limit maybe to show the entire animation\n\nCreate a javascript animation of the time-series running inline in the notebook:\n\n# HTML(ani.to_jshtml())\n\nDelete the dummy png that was saved to the current working directory while generating the javascript animation in the last code cell.\n\n# try:\n#     Path('/home/jovyan/notebooks/SAR_Training/English/Master/None0000000.png').unlink()\n# except FileNotFoundError:\n#     pass\n\nSave the animation (animation.gif):\n\nani.save(plot_dir/f'animation.gif', writer='pillow', fps=2)\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-4-3-create-time-series-animation","position":21},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"5. Computation and Visualization of Time Series Metrics"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-5-computation-and-visualization-of-time-series-metrics","position":22},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"5. Computation and Visualization of Time Series Metrics"},"content":"Once a time-series was constructed, we can compute a set of metrics for each pixel in the stack:\n\nMean\n\nMedian\n\nMaximum\n\nMinimum\n\nRange (Maximum - Minimum)\n\n5th Percentile\n\n95th Percentile\n\nPRange (95th - 5th Percentile)\n\nVariance\n\nCoefficient of Variation (Variance/Mean)\n\nFirst, we mask out pixels that are zero (e.g. beyond the edge of the swath). Then we calculate the time series metrics:\n\n# mask = (rasterstack == 0)\n# raster = np.ma.array(convert(rasterstack), mask=mask, dtype=np.float64)\n\n\n\n%%time\n# calc metric in power\nmetrics = timeseries_metrics(da)\nmetrics.load()\nmetrics\n\n# metrics.keys()\n\nLet’s look at the histograms for the time series variance and coeficient of variation to aid displaying those images:\n\n# fig, ax = plt.subplots(1,2,figsize=(16,4))\n# ax[0].hist(metrics['var'].flatten(), bins=100, range=np.nanpercentile(metrics['var'], [1,99]))\n# ax[1].hist(metrics['CV'].flatten(), bins=100, range=np.nanpercentile(metrics['CV'], [1,99]))\n# _ = ax[0].set_title('Variance')\n# _ = ax[1].set_title('Coefficient of Variation')\n\nnp.min(cv)\n\nnp.max(cv)\n\nlen(cv)\n\nfrom matplotlib import pyplot as plt\n\nfig, ax = plt.subplots(1,2,figsize=(9, 3))\n\nvar = metrics[\"var\"].values.ravel()\nax[0].hist(var, bins=100, range=np.nanpercentile(var, [1,99]))\nax[0].set_title('Variance')\n\ncv = metrics[\"CV\"].values.ravel()\nax[1].hist(cv, bins=100, range=np.nanpercentile(cv, [1,99]))\nax[1].set_title('Coefficient of Variation')\n\nplt.show()\n\n# # List the metrics keys you want to plot\n# metric_keys=['mean', 'median', 'max', 'min', \n#              'p95', 'p5', 'prange', 'var', 'std', 'CV']\n# fig= plt.figure(figsize=(16,40))\n# idx=1\n# for i in metric_keys:\n#     ax = fig.add_subplot(5,2,idx)\n#     vmin, vmax = np.nanpercentile(metrics[i], [1, 99])\n#     ax.imshow(metrics[i],vmin=vmin,vmax=vmax,cmap='inferno')\n#     ax.set_title(i.upper())\n#     ax.axis('off')\n#     idx+=1\n\nmetrics\n\n# List the metrics keys you want to plot\nmetric_keys=['mean', 'p50', 'max', 'min', \n             'p95', 'p05', 'prange', 'var', 'std', 'CV']\nfig= plt.figure(figsize=(16,40))\nidx=1\nfor i in metric_keys:\n    ax = fig.add_subplot(5,2,idx)\n    vmin, vmax = np.nanpercentile(metrics[i], [1, 99])\n    ax.imshow(metrics[i],vmin=vmin,vmax=vmax,cmap='inferno')\n    ax.set_title(i.upper())\n    ax.axis('off')\n    idx+=1\n\nYou might have noticed white patches in the images above. These do not contain any data. The reason is that they are in the radar shadow of terrain that is closer to the satellite.","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-5-computation-and-visualization-of-time-series-metrics","position":23},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"6. Some Popular SAR Change Detection Methods"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-some-popular-sar-change-detection-methods","position":24},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"6. Some Popular SAR Change Detection Methods"},"content":"This section will introduce you to the following popular and simple change detection methods:\n\nTime series metrics  95^{th} and 5^{th} percentile difference and standard deviation thresholding\n\nTime series coefficient of variation thresholding","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-some-popular-sar-change-detection-methods","position":25},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"6.1 Change Detection with the Percentile Difference and the Variance Threshold Method","lvl2":"6. Some Popular SAR Change Detection Methods"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-1-change-detection-with-the-percentile-difference-and-the-variance-threshold-method","position":26},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"6.1 Change Detection with the Percentile Difference and the Variance Threshold Method","lvl2":"6. Some Popular SAR Change Detection Methods"},"content":"In this method we find thresholds on the 95^{th} and 5^{th} percentile difference or the temporal pixel-by-pixel gray value cariance. Let’s start with the 95^{th} and 5^{th} percentile difference. The advantage to look at percentiles verus maximum minus minimum is that it is more robust to outliers.\n\nFirst, let us define a function for plotting histograms:\n\ndef plot_histogram_cdf(metric='std'):\n    plt.rcParams.update({'font.size': 12})\n    fig = plt.figure(figsize=(14, 4)) # Initialize figure with a size\n    ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n    ax2 = fig.add_subplot(122)\n\n    h = ax1.hist(\n        metrics[metric].values.ravel(), range=np.nanpercentile(metrics[metric], [1, 99]))\n    ax1.xaxis.set_label_text(f'{metric}')\n    ax1.set_title('Histogram')\n\n    n, bins, patches = ax2.hist(\n        metrics[metric].values.ravel(), range=np.nanpercentile(metrics[metric], [1, 99]),\n        cumulative='True', density='True', histtype='step', label='Empirical')\n\n    ax2.xaxis.set_label_text(f'{metric}')\n    ax2.set_title('CDF')\n\n    outind = np.where(n > 0.95)   \n    threshind = np.min(outind)\n    thresh = bins[threshind]\n    ax1.axvline(thresh,color='red')\n    _ = ax2.axvline(thresh,color='red')\n    plt.savefig(plot_dir/f'{metric}_histogram.png',\n                dpi=200, transparent='true')\n\nNow let’s look at the 95th - 5th percentile range\n\nplot_histogram_cdf(metric='prange')\n\nLet’s visualize the 5% of all pixels with the largest (95th - 5th percentile) difference in the time series. We will refer to the pixels (x,y) that exceed this threshold t as likely change pixels (cp):\n\n{cp}_{x,y} = P_{x,y}^{95th} - P_{x,y}^{5th} > t\n\nIf we define t to correspond to the 5% of pixels with highest (95th - 5th percentile) difference, the image looks like:\n\ndef plot_threshold_classifier(metric='prange', percentage_cutoff=5):\n    plt.figure(figsize=(8,8))\n    thresh = np.nanpercentile(metrics[metric], 100 - percentage_cutoff)\n    mask = metrics[metric] < thresh # For display we prepare the inverse mask\n    plt.imshow(mask, cmap='gray')\n    _=plt.title(f'Threshold Classifier on {metric} > %1.8f' % thresh)\n    plt.savefig(plot_dir/f'changes_{metric}.png',\n            dpi=200, transparent='true')\n    return np.logical_not(mask)\n\nmetric = 'prange'\nmasks = {metric: plot_threshold_classifier(metric=metric)}\n\nInstead of applying a threshold on the 95th - 5th percentile difference data, we can also attempt to threshold other metrics. The standard deviation (or variance) variable seems a useful indicator for change as it identifies pixels for which radar brightness has changed strongly within the time series. Hence, in the following we use this metric for change identification according to:\n\n{cp}_{x,y} = \\sigma > t\n\nwith t=CDF_{\\sigma} > 0.95 (5% pixels with highest standard deviation):\n\nplot_histogram_cdf(metric='std')\n\nmetric = 'std'\nmasks[metric] = plot_threshold_classifier(metric=metric)\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-1-change-detection-with-the-percentile-difference-and-the-variance-threshold-method","position":27},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"6.2 Change Detection with the Coefficient of Variation Method","lvl2":"6. Some Popular SAR Change Detection Methods"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-2-change-detection-with-the-coefficient-of-variation-method","position":28},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"6.2 Change Detection with the Coefficient of Variation Method","lvl2":"6. Some Popular SAR Change Detection Methods"},"content":"We can also set a threshold t for the coefficient of variation image\nto classify change in the time series:\n\n{CV}_{x,y} = \\frac{\\sigma_{x,y}}{\\overline{X}_{x,y}} > t\n\nLet’s look at the histogram and the Cumulative Distribution Function (CDF) of the coefficient of variation:\n\nplot_histogram_cdf(metric='CV')\n\nWith a threshold of t=CDF_{CV} > 0.95 (5% pixels with highest variance) the change pixels would look like the following image:\n\nmetric = 'CV'\nmasks[metric] = plot_threshold_classifier(metric=metric)\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-2-change-detection-with-the-coefficient-of-variation-method","position":29},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"6.3 Pair-wise change detection","lvl2":"6. Some Popular SAR Change Detection Methods"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-3-pair-wise-change-detection","position":30},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"6.3 Pair-wise change detection","lvl2":"6. Some Popular SAR Change Detection Methods"},"content":"To analyze temporal changes between two images, it is useful to compute metrics that are sensitive to discrepancies between the two images. In radar remote sensing, the standard way is to look at ratios (in the linearly scaled power domain) or, equivalently, at differences in the logarithmic dB domain.\n\n# dates = ('2018-05-27', '2018-06-08') # around first eruption\n\n# # convert to datetime objects\n# dates_ = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n\n# # get the indices in one line\n# dates_ind = [np.argmin(np.abs(date - tindex)) for date in dates_]\n# print(f'Comparing image {dates_ind[0]} from {tindex[dates_ind[0]].date()} with {dates_ind[1]} from {tindex[dates_ind[1]].date()}')\n\ndates = ('2025-11-03', '2025-11-07') # around first eruption\n\n# convert to datetime objects\ndates_ = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n\n# get the indices in one line\ndates_ind = [np.argmin(np.abs(date - tindex)) for date in dates_]\nprint(f'Comparing image {dates_ind[0]} from {tindex[dates_ind[0]].date()} with {dates_ind[1]} from {tindex[dates_ind[1]].date()}')\n\nda.time\n\nCompute the log ratio in dB, corresponding to the difference in dB\n\n# ratiodB = 10 * np.ma.log10(np.ma.divide(rasterstack[dates_ind[1], ...], rasterstack[dates_ind[0], ...]))\n\ndate_0 = da.sel(time=\"2025-11-03\").squeeze(\"time\", drop=True)\ndate_1 = da.sel(time=\"2025-11-07\").squeeze(\"time\", drop=True)\n\nratiodB = 10 * np.log10(date_1 / date_0)\nratiodB\n\nLet us manually choose a threshold this time\n\nthresh is the threshold, e.g. -2 dB\n\nthresh_type determines whether we mask everything below that (lower) or above (upper)\n\n# thresh = -2\n# thresh_type = 'lower' #'lower': mask everything below thresh, 'upper': mask everything above\n\n# copy_absRatiod = np.copy(np.abs(ratiodB))\n# # dynamic_range = np.nanpercentile(np.abs(ratiodB), 99)\n# dynamic_range = np.nanpercentile(copy_absRatiod, 99)\n# fig, axs = plt.subplots(ncols=3, nrows=1)\n# fig.set_size_inches(20, 4)\n# plt.subplots_adjust(hspace=0.4, right=0.85)\n\n# # h = axs[0].hist(\n# #         ratiodB.flatten(), bins=200, range=np.nanpercentile(ratiodB, [0.1, 99.9]))\n\n# h = axs[0].hist(\n#         ratiodB.flatten(), bins=200, range=np.nanpercentile(np.copy(ratiodB), [0.1, 99.9]))\n\n# axs[0].xaxis.set_label_text(f'difference [dB]')\n# axs[0].set_title('Histogram')\n# im0 = axs[1].imshow(ratiodB, cmap='RdBu', vmin=-dynamic_range, vmax=dynamic_range)\n# cbar = fig.colorbar(im0, orientation='vertical', ax=axs.ravel().tolist(), shrink=0.7)\n# cbar.set_label('[dB]')\n# axs[1].set_title('Image')\n# mask = (ratiodB > thresh if thresh_type == 'lower' else ratiodB < thresh).astype(np.int8)\n# axs[2].imshow(mask, cmap='gray')\n# axs[2].set_title('Mask')\n# fig.suptitle(f'{tindex[dates_ind[0]].date()} {tindex[dates_ind[0]].date()}')\n# logratiolabel = f'logratio_{tindex[dates_ind[0]].date()}_{tindex[dates_ind[0]].date()}'\n# plt.savefig(product_path/f'{logratiolabel}.png',\n#             dpi=200, transparent='true')\n# masks[logratiolabel] = np.logical_not(mask)\n\n# np.nanpercentile(np.copy(ratiodB), [0.1, 99.9])\nlow, high = (ratiodB.quantile([0.01, 0.99]))\nlow.compute().item()\n\nhigh.compute().item()\n\nthresh = -2\na = ratiodB < thresh\na.max().compute().item()\n\nthresh = -2\nthresh_type = 'lower' #'lower': mask everything below thresh, 'upper': mask everything above\n\nabs_ratiodB = np.abs(ratiodB)\ndynamic_range = abs_ratiodB.quantile(0.99, skipna=True).compute().item()\n\n\nfig, axs = plt.subplots(ncols=3, nrows=1)\nfig.set_size_inches(20, 4)\nplt.subplots_adjust(hspace=0.4, right=0.85)\n\n# h = axs[0].hist(\n#         ratiodB.flatten(), bins=200, range=np.nanpercentile(ratiodB, [0.1, 99.9]))\n\naxs[0].hist(\n        ratiodB.values.ravel(), bins=10, range=np.nanpercentile(ratiodB, [0.1, 99.9]))\n\naxs[0].xaxis.set_label_text(f'difference [dB]')\naxs[0].set_title('Histogram')\n\nim0 = axs[1].imshow(ratiodB, cmap='RdBu', vmin=-dynamic_range, vmax=dynamic_range)\ncbar = fig.colorbar(im0, orientation='vertical', ax=axs.ravel().tolist(), shrink=0.7)\ncbar.set_label('[dB]')\naxs[1].set_title('Image')\n\nmask = (ratiodB > thresh if thresh_type == 'lower' else ratiodB < thresh).astype(np.int8)\n\naxs[2].imshow(mask, cmap='gray')\naxs[2].set_title('Mask')\nfig.suptitle(f'{tindex[dates_ind[0]].date()} {tindex[dates_ind[0]].date()}')\nlogratiolabel = f'logratio_{tindex[dates_ind[0]].date()}_{tindex[dates_ind[0]].date()}'\nplt.savefig(product_path/f'{logratiolabel}.png',\n            dpi=200, transparent='true')\nmasks[logratiolabel] = np.logical_not(mask)\n\n\n\nDo you think the threshold is appropriate? If not, try adjusting it.\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-6-3-pair-wise-change-detection","position":31},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"type":"lvl2","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-write-our-change-detection-results-and-metrics-images-to-geotiff-files","position":32},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"content":"","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-write-our-change-detection-results-and-metrics-images-to-geotiff-files","position":33},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.1 Determine Output Geometry","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-1-determine-output-geometry","position":34},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.1 Determine Output Geometry","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"content":"First, we need to set the correct geotransformation and projection information. We retrieve the values from the input images:\n\nproj=img.GetProjection()\ngeotrans=list(img.GetGeoTransform())\ngeotrans\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-1-determine-output-geometry","position":35},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.2 Output Time Series Metrics Images","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-2-output-time-series-metrics-images","position":36},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.2 Output Time Series Metrics Images","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"content":"We use the root of the time series data stack name and append a ts_metrics<metric>.tif ending as filenames:\n\n# Time Series Metrics as image:\n# We make a new subdirectory where we will store the images\n\ndirname = analysis_dir/f\"{str(analysis_dir).split('/')[-1]}_tsmetrics_{pol}\"\nif not dirname.exists():\n    dirname.mkdir()\n\nprint(dirname)\n\nNow we can output the individual metrics as GeoTIFF images:\n\nnames=[] # List to keep track of all the names\nfor metric in metrics:\n    name_ = dirname/f'{metric}_{labeldB}.tif'\n    create_geotiff(str(name_), metrics[metric], gdal.GDT_Float32, np.nan, [metric],\n                  geo_t=geotrans, projection=proj)\n    names.append(str(name_))\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-2-output-time-series-metrics-images","position":37},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.3 Build a Virtual Raster Table on the Metrics GeoTIFF images","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-3-build-a-virtual-raster-table-on-the-metrics-geotiff-images","position":38},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.3 Build a Virtual Raster Table on the Metrics GeoTIFF images","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"content":"To tie the images into one new raster stack of time series metrics we build a virtual raster table with all the metrics.\n\nTrick: Use ’ '.join(names) to build one long string of names separated by a space as input to gdalbuildvrt:\n\ncmd=f'gdalbuildvrt -separate -overwrite -vrtnodata nan {str(dirname)}' +\\\nf'_{labeldB}.vrt '+' '.join(names)\nprint(cmd)\n\n_ = system(cmd)\n\n","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-3-build-a-virtual-raster-table-on-the-metrics-geotiff-images","position":39},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.4 Create GeoTIFFs for the Change Iamges from our Four Change Detection Attempts","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"type":"lvl3","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-4-create-geotiffs-for-the-change-iamges-from-our-four-change-detection-attempts","position":40},{"hierarchy":{"lvl1":"An Introduction to Simple SAR Change Detection Methods","lvl3":"7.4 Create GeoTIFFs for the Change Iamges from our Four Change Detection Attempts","lvl2":"7. Write Our Change Detection Results and Metrics Images to GeoTIFF files"},"content":"We are going to write GeoTIFF output files that stores the results from the classifiers:\n\nfor metric in masks:  \n    fnmetric = dirname/f\"{str(analysis_dir).split('/')[-1]}_{labeldB}_{metric}_thresholds.tif\"\n    print(fnmetric)\n\n    create_geotiff(str(fnmetric), masks[metric], gdal.GDT_Byte, np.nan, \n                  geo_t=geotrans, projection=proj)\n\nSARChangeDetectionMethods_From_Prepared_Data_Stack - Version 1.4.2 - November 2021\n\nVersion Changes\n\nupdate get_date function","type":"content","url":"/notebooks/nisar-gcov-sarchangedetectionmethods#id-7-4-create-geotiffs-for-the-change-iamges-from-our-four-change-detection-attempts","position":41},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series"},"type":"lvl1","url":"/notebooks/nisar-gcov-time-series-example","position":0},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series"},"content":"","type":"content","url":"/notebooks/nisar-gcov-time-series-example","position":1},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series"},"type":"lvl1","url":"/notebooks/nisar-gcov-time-series-example#explore-an-example-nisar-gcov-backscatter-time-series","position":2},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series"},"content":"","type":"content","url":"/notebooks/nisar-gcov-time-series-example#explore-an-example-nisar-gcov-backscatter-time-series","position":3},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, Earth Big Data, LLC"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#franz-j-meyer-university-of-alaska-fairbanks-josef-kellndorfer-earth-big-data-llc","position":4},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, Earth Big Data, LLC"},"content":"Updated to support NISAR GCOV data by Alex Lewandowski, 2025-09-12\n\n\n\nThis notebook introduces the analysis of multi-temporal SAR backscatter image data stacks using the NISAR L2 GCOV data product. GCOV data are a radiometrically terrain corrected and geocoded product that provides backscatter in \\gamma^{0} at linear (power) scale.\n\nThis notebook covers the following data analysis concepts:\n\nSearch and download a stack of NISAR GCOV data\n\nLoad GCOV data into an xarray.Dataset\n\nSubset:\n\nSpatially, in UTM or Lat/Lon coords\n\nTemporally\n\nBy frequency\n\nBy polarization\n\nConvert between Power and dB scales\n\nCompute time series means\n\nPlot Backscatter\n\nImage data\n\nHistograms\n\nMeans\n\nAnimations\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#franz-j-meyer-university-of-alaska-fairbanks-josef-kellndorfer-earth-big-data-llc","position":5},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"0. Search and Access Data Stack"},"type":"lvl2","url":"/notebooks/nisar-gcov-time-series-example#id-0-search-and-access-data-stack","position":6},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"0. Search and Access Data Stack"},"content":"\n\nThis notebook will be access an x-image deep SAR data stack over blank for a first experience with time series processing. The data were acquired by NISAR’s L-band sensor and are available from the \n\nAlaska Satellite Facility.\n\nTODO: Update description below and plot at right when a real dataset is available\n\n~~Nepal is an interesting site for this analysis due to the significant seasonality of precipitation that is characteristic for this region. Nepal is said to have five seasons: spring, summer, monsoon, autumn and winter. Precipitation is low in the winter (November - March) and peaks dramatically in the summer, with top rain rates in July, August, and September (see figure to the right). As SAR is sensitive to changes in soil moisture, these weather patterns have a noticeable impact on the Radar Cross Section (\\sigma) time series information.~~\n\nWe will analyze the variation of \\gamma^{0} values over time and will interpret them in the context of rainfall rates in the imaged area.\n\nCreate directories to hold the time series data and output plots\n\nfrom pathlib import Path\n\ntime_series_example_dir = Path.cwd() / \"time_series_example\"\n\ndata_dir = time_series_example_dir / \"data\"\ndata_dir.mkdir(parents=True, exist_ok=True)\n\nplot_dir = time_series_example_dir / \"plots\"\nplot_dir.mkdir(exist_ok=True)\n\nUse asf_search to search and download GCOV data\n\nimport os\nimport asf_search as asf\n# from getpass import getpass\n\n\nwkt = \"POLYGON((-57.759 -3.5099,-56.459 -3.5099,-56.459 -2.6352,-57.759 -2.6352,-57.759 -3.5099))\"\n\nopts=asf.ASFSearchOptions(**{\n    \"maxResults\": 250,\n    \"intersectsWith\": wkt,\n    \"processingLevel\": [\n        \"GCOV\"\n    ],\n    \"dataset\": [\n        \"NISAR\"\n    ],\n    \"productionConfiguration\": [\n        \"PR\"\n    ],\n    \"host\": \"cmr.uat.earthdata.nasa.gov\"\n})\n\nsession = asf.ASFSession(cmr_host='cmr.uat.earthdata.nasa.gov')\n# session.auth_with_token(getpass('UAT EDL token'))\nsession.auth_with_token(os.environ[\"UAT_TOKEN\"])\n\nresponse = asf.search(opts=opts)\n\nhdf5_files = response.find_urls(extension='.h5', pattern=r'^(?!.*STATS).*DHDH.*', directAccess=False)\nasf.download_urls(hdf5_files, data_dir, session=session, processes=4)\n\nSample data workaround\n\nTODO: Remove when there is real NISAR data\n\nWe only have one GCOV sample product, so duplicate the file to fake a time series\n\n# TODO: Delete when we have real NISAR data\n# Duplicates the one sample GCOV file we have\nimport shutil\n\nf = list(data_dir.glob('*.h5'))[0]\nfor i in range(7): \n    shutil.copy(f, f.parent / f\"{f.stem}_{i}.h5\")\n\nCollect the paths to the downloaded data\n\ngcov_files = sorted(list(data_dir.glob(\"*.h5\")))\ngcov_files\n\nExplore the available groups, datasets, and attributes in one of the GCOV HDF5 files\n\nimport nexusformat.nexus as nx\n\nf = nx.nxload(gcov_files[0])\nprint(f.tree)\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-0-search-and-access-data-stack","position":7},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"1. Load the Data with xarray"},"type":"lvl2","url":"/notebooks/nisar-gcov-time-series-example#id-1-load-the-data-with-xarray","position":8},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"1. Load the Data with xarray"},"content":"Lazy load the data stack into an xarray.Dataset\n\nNISAR data is distributed in HDF5, not NetCDF. The NISAR HDF5 data does not define time, x, and y coordinates or map them to variables. Therefor, we cannot simply use xarray.open_mfdataset to load the data-cube. Instead, we must define the coordinates and variables, and build the dataset ourselves.\n\nUse the open_gcov helper function below to load the data into an xarray.Dataset\n\nimport re\nimport h5py\nimport numpy as np\nimport xarray as xr\nimport dask.array as da\nfrom dask import delayed\n\n_date_regex = re.compile(r\"_(\\d{8}T\\d{6})_\")\ndef _get_ts(filename):\n    match = _date_regex.search(filename)\n    if match:\n        ts_str = match.group(1)\n        return np.datetime64(f\"{ts_str[:4]}-{ts_str[4:6]}-{ts_str[6:8]}T{ts_str[9:11]}:{ts_str[11:13]}:{ts_str[13:15]}\") \n    return np.datetime64(\"NaT\")\n\ndef open_gcov(gcov_paths, vars_to_load=(\"HHHH\", \"HVHV\", \"mask\", \"numberOfLooks\", \"rtcGammaToSigmaFactor\"), freqs=(\"A\",\"B\"), max_xy_chunk=2048):\n    gcov_paths = sorted(gcov_paths)\n    group = {f: f\"/science/LSAR/GCOV/grids/frequency{f}\" for f in freqs}\n    with h5py.File(gcov_paths[0], \"r\") as f0:\n        g = f0[group[freqs[0]]]\n        x, y = g[\"xCoordinates\"][...], g[\"yCoordinates\"][...]\n        proj = g[\"projection\"][()]\n    ny, nx = len(y), len(x)\n    time = np.array([_get_ts(p.name) for p in gcov_paths])\n    chunks = (1, 1, min(ny, max_xy_chunk), min(nx, max_xy_chunk))  # (time, frequency, y, x)\n\n    data_vars = {}\n    for v in vars_to_load:\n        per_freq = []\n        for freq in freqs:\n            with h5py.File(gcov_paths[0], \"r\") as f0:\n                dt = f0[f\"{group[freq]}/{v}\"].dtype\n            planes = [da.from_delayed(delayed(lambda p, d: h5py.File(p,\"r\")[d][...])(p, f\"{group[freq]}/{v}\"),\n                                      shape=(ny, nx), dtype=dt)[None, None, ...]\n                      for p in gcov_paths]\n            per_freq.append(da.concatenate(planes, axis=0))\n        stacked = da.concatenate(per_freq, axis=1).rechunk(chunks)\n        data_vars[v] = ((\"time\",\"frequency\",\"y\",\"x\"), stacked)\n\n    return xr.Dataset(\n        data_vars=data_vars,\n        coords={\"time\": time, \"frequency\": np.array(list(freqs)), \"y\": y, \"x\": x},\n        attrs={\"source\": \"NISAR L2 GCOV\", \"projection\": proj},\n    )\n\nUse the open_gcov function to load the data from HDF5\n\nNote that open_gcov defaults to loading all rasters into the Dataset, and in all dimensions (time, frequency, y, x)\n\nds = open_gcov(gcov_files)\nds\n\n\n\nWe loaded some data variables that won’t be used in this notebook.\n\nNow load only the HHHH and HVHV backscatter rasters\n\nds = open_gcov(gcov_files, vars_to_load=(\"HHHH\", \"HVHV\"))\nds\n\n\n\nSample data workaround\n\nTODO: Remove when there is real NISAR data\n\nTo fake a time series with our duplicated sample data:\n\nUpdate the time dimension with fake dates\n\nAdjust the backscatter for each date to make our plots more interesting\n\n# TODO: remove this when there is real NISAR data\n# Fakes a time series by updating dates and backscatter\n\nimport pandas as pd\n\nfake_times = pd.date_range(\n    start=\"2025-11-02T22:06:39\",\n    periods=ds.sizes[\"time\"],\n    freq=\"D\"\n)\n\nds = ds.assign_coords(time=fake_times)\n\n# adjust each duplicated time step's backscatter values for better test visualization\nfactors = 1 + 0.3 * np.sin(np.linspace(0, 2*np.pi, ds.sizes[\"time\"]))\nscaled = ds * xr.DataArray(factors, dims=[\"time\"])\nscaled = scaled.assign_attrs(ds.attrs)\nds = scaled\nds\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-1-load-the-data-with-xarray","position":9},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"2. General Examples"},"type":"lvl2","url":"/notebooks/nisar-gcov-time-series-example#id-2-general-examples","position":10},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"2. General Examples"},"content":"Before we work with the time series, here are a couple of examples related to subsetting and plotting.","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-2-general-examples","position":11},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"2.1. How to Subset the Data","lvl2":"2. General Examples"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-2-1-how-to-subset-the-data","position":12},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"2.1. How to Subset the Data","lvl2":"2. General Examples"},"content":"Time series can contain a large amount of data, so it is helpful to subset the data to the smallest appropriate area of interest.\n\nSo far, we have only lazy-loaded the data. Since we have not computed any values, we have not stored much in memory. However when we convert from Power to dB or perform statistics, we will need to load data into memory, so we should define a subset of the data first, and only load what we need.\n\nWe can subset by spatial coordinates, temporal bounds, and/or frequency.\n\nSubset to a spatial extent by supplying coordinates in the dataset’s native UTM\n\n# Note that you do not have to supply exact existing coords from your dataset for your slice bounds. \n# If your x coords are [0,3,6,9,12,15,18,21], using a slice(2, 14) will give you [3,6,9,12]\n\nsubset_utm = ds.sel(\n    x=slice(400000.0, 500000.0),\n    y=slice(9700000.0, 9600000.0),\n    time=slice(\"2025-11-02\", \"2025-11-11\"),\n    frequency=[\"A\", \"B\"]\n)\nsubset_utm\n\nNow subset to a spatial extent by supplying coordinates in WGS84 (Lat/Lon)\n\nrioxarray allows us to subset from coordinates in a different CRS while leaving the subset in its original UTM.\n\nSubsetting in WGS84 is useful if you are grabbing some coordinates from Google Maps or Vertex.\n\n# Provide your subset coords in 4326 (lat/lon), but keep the dataset in UTM.\nimport rioxarray\n\nds = ds.rio.write_crs(f\"EPSG:{ds.projection}\")\nsubset_with_lat_lon_coords = ds.rio.clip_box(\n    minx=-57.5, miny=-3.6,\n    maxx=-56.5, maxy=-2.6, \n    crs=\"EPSG:4326\"\n).sel(\n    time=slice(\"2025-11-02\", \"2025-11-07\"),\n    frequency=[\"A\", \"B\"]\n)\nsubset_with_lat_lon_coords\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-2-1-how-to-subset-the-data","position":13},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"2.2. Write an Example Plotting Function","lvl2":"2. General Examples"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-2-2-write-an-example-plotting-function","position":14},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"2.2. Write an Example Plotting Function","lvl2":"2. General Examples"},"content":"Matplotlib allows a great deal of flexibility in displaying imagery and generating plots.\n\nHere is an example function that displays a single raster alongside its associated histogram.\n\nWe won’t use this function in the notebook but it demonstrates how you can wrap your plotting code in functions to make them easily reusable.\n\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\ndef show_image_histogram_da(\n    da: xr.DataArray,\n    vmin: float | None = None,\n    vmax: float | None = None,\n    image_downsample: int = 1,\n    bins: int = 200,\n    output_path: str | None = None,\n):\n    \"\"\"\n    Displays a raster image alongside a histogram showing its distribution. The image raster may\n    be downsampled for efficient visualizing, however the histogram is generated using the original\n    data, in the range defined by vmin and vmax.\n\n    If vmin and vmax are not provided, the 0.05 and 0.95 quantiles will be used to remove outliers.\n    \n    da: DataArray containing raster data\n    vmin: Minimum image value mapped to matplotlib colormap and included in histogram\n    vmax: Maximum image value mapped to matplotlib colormap and included in histogram\n    image_downsample: Allows downsampling of image for faster visualization (does not downsample histogram) \n    bins: Histogram bin size\n    output_path: An output path for optionally saving the plot\n    \"\"\"\n\n    da = da.squeeze()\n\n    downsampled_da = da.isel(y=slice(None, None, image_downsample), \n                     x=slice(None, None, image_downsample)) if image_downsample > 1 else da\n\n    if vmin is None or vmax is None:\n        q = da.quantile([0.05, 0.95], skipna=True)\n        if vmin is None:\n            vmin = float(q.sel(quantile=0.05).values)\n        if vmax is None:\n            vmax = float(q.sel(quantile=0.95).values)\n\n    fig = plt.figure(figsize=(16, 8))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2)   \n    \n    polarization = f\"Polarization: {da.name}\"\n    date = da.time.values.astype(str).split(\"T\")[0]\n    frequency = f\"Frequency: {da.frequency.values.item()}\"\n    title_parts = [da.source] if \"source\" in da.attrs else []\n    title_parts.extend([polarization, frequency, date])\n    title = \" | \".join(title_parts)\n\n    downsampled_da.plot.imshow(ax=ax1, cmap=\"gray\", add_colorbar=False, vmin=vmin, vmax=vmax)\n    ax1.set_title(title)\n\n    if \"projection\" in raster.attrs:\n        xlabel = \"Longitude\" if da.projection == 4326 else \"Easting\"\n        ylabel = \"Latitude\" if da.projection == 4326 else \"Northing\"\n        ax1.set_xlabel(xlabel)\n        ax1.set_ylabel(ylabel)\n\n    da.plot.hist(ax=ax2, bins=bins, range=(vmin, vmax))\n    ax2.set_xlabel(\"Backscatter\")\n    ax2.set_title(f\"Histogram ({bins} bins)\")\n\n    fig.tight_layout()\n\n    if output_path:\n        plt.savefig(output_path, dpi=300, transparent=True)\n\n    return fig, (ax1, ax2)\n\nWe won’t be calling our new function elsewhere in this notebook, so test it now:\n\nNote:\n\nWe are passing an output_path to save a copy of the plot\n\nThe highly skewed distribution indicates that the data are in Power scale, which is expected for NISAR GCOV products\n\n%%time\nsubset = subset_utm\ndate = \"2025-11-02\"\nfreq = \"A\"\npolarization = \"HHHH\"\n\nraster = subset.sel(time=date, frequency=freq)[polarization]\nraster = raster.assign_attrs({**subset.attrs, **raster.attrs}) # attach global Dataset attributes to DataArray\n\nshow_image_histogram_da(raster,\n                        vmin=0.0,\n                        vmax=1.7e-6,\n                        image_downsample=4,\n                        output_path=plot_dir/f'image_and_hist_{date}_{polarization}_{freq}.png')\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-2-2-write-an-example-plotting-function","position":15},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl2","url":"/notebooks/nisar-gcov-time-series-example#id-3-sar-time-series-visualization-animation-and-analysis","position":16},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"This section introduces you to the handling and analysis of SAR time series stacks. A focus will be put on time series visualizations, which allow us to inspect time series in more depth.\n\nAnimations will display interactively, and be saved as gifs.","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-sar-time-series-visualization-animation-and-analysis","position":17},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.1. Subset the Data","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-3-1-subset-the-data","position":18},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.1. Subset the Data","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"Create a new subset AOI\n\nsubset = ds.sel(\n    x=slice(450000.0, 460000.0),\n    y=slice(9630000.0, 9620000.0),\n    time=slice(\"2025-11-02\", \"2025-11-08\"),\n    frequency=[\"A\", \"B\"]\n)\nsubset\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-1-subset-the-data","position":19},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.2. Visually confirm the subset AOI’s location","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-3-2-visually-confirm-the-subset-aois-location","position":20},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.2. Visually confirm the subset AOI’s location","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"Plot the subset bounds on a basemap to verify the correct location\n\nimport cartopy.crs as ccrs\nimport contextily as ctx\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfig = plt.figure(figsize=(10,8))     \n\nax = fig.add_subplot(1, 1, 1, projection=ccrs.epsg(3857))\n\nminx, miny, maxx, maxy = ds.rio.transform_bounds(\"EPSG:3857\", densify_pts=21)\nax.set_extent(\n    [minx, maxx, miny, maxy],\n    crs=ccrs.epsg(3857))\n\n\nctx.add_basemap(ax, crs=\"EPSG:3857\", source=ctx.providers.Esri.WorldImagery)\nctx.add_basemap(ax, crs=\"EPSG:3857\", source=ctx.providers.OpenStreetMap.Mapnik, alpha=0.5)\n\nsub_minx, sub_miny, sub_maxx, sub_maxy = subset.rio.transform_bounds(\"EPSG:3857\", densify_pts=21)\nrect = patches.Rectangle(\n    (sub_minx, sub_miny),\n    sub_maxx - sub_minx,\n    sub_maxy - sub_miny, \n    linewidth=2, \n    edgecolor=\"red\", \n    facecolor=\"none\",\n    label=\"Subset AOI\",\n    transform=ccrs.epsg(3857)\n)\nax.add_patch(rect)\n\nax.legend(handles=[rect])\nplt.show()\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-2-visually-confirm-the-subset-aois-location","position":21},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.3 Data Conversion between dB and Power Scales","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-3-3-data-conversion-between-db-and-power-scales","position":22},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.3 Data Conversion between dB and Power Scales","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"Focused SAR image data may come in uncalibrated digital numbers (DN) and need to be calibrated to correspond to proper radar cross section information. However, NISAR data is already radiometrically calibrated and has a scaling factor of 1.0, so we do not need to worry about this.\n\nThe data at hand are radiometrically terrain corrected images, which are often expressed as terrain flattened \\gamma^0 backscattering coefficients. For forest and land cover monitoring applications \\gamma^o is the preferred metric.\n\nWe often visualize backscatter in log scale (dB), as plotting in a linear (Power) scale may obscure subtleties. However, we must compute statistics in linear scale, so there you may have need to convert back and forth between Power and dB.\n\nNISAR GCOV data are provided in Power scale.\n\nConvert the HHHH, frequency A subset data from power to dB\n\nTo convert from power to dB, apply: \\gamma^o_{dB} = 10 {\\log_{10}(\\gamma^o_{power})}\n\nNote that this is the first time we load this subset into memory, which is why the code cell takes a little time to run (~15 seconds)\n\n%%time\n# load subset_stack into memory once now to avoid multiple loads in subsequent code cells\nsubset_db = 10*np.log10(subset.sel(frequency=\"A\").HHHH)\nsubset_db.load()\nsubset_db\n\nPlot the histogram of the dB data and confirm a normal distribution\n\nax = subset_db.values.ravel()\nplt.hist(ax, bins=50)\nplt.show()\n\nConvert from dB back to power\n\nWhile dB-scaled images are often “visually pleasing”, they are often not a good basis for mathematical operations on data. For instance, when we compute the mean of observations, it makes a difference whether we do that in power or dB scale. Since dB scale is a logarithmic scale, we cannot simply average data in that scale.\n\nPlease note that the correct scale in which operations need to be performed is the power scale. This is critical, e.g. when speckle filters are applied, spatial operations like block averaging are performed, or time series are analyzed.\n\nTo convert from dB to power, apply: \\gamma^o_{pwr} = 10^{\\frac{\\gamma^o_{dB}}{10}}\n\nsubset_pwr = np.power(10.0, subset_db/10.0)\nax = subset_pwr.values.ravel()\nplt.hist(ax, bins=50)\nplt.show()\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-3-data-conversion-between-db-and-power-scales","position":23},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.4 Create a Time Series Animation from the dB Subset","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-3-4-create-a-time-series-animation-from-the-db-subset","position":24},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.4 Create a Time Series Animation from the dB Subset","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"\n\n%%capture\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.animation import FFMpegWriter, PillowWriter\n\nvmin = subset_db.quantile(0.05, skipna=True).values.item()\nvmax = subset_db.quantile(0.95, skipna=True).values.item()\n\nfig, ax = plt.subplots(figsize=(6, 6), )\nframe_0 = subset_db.isel(time=0).values\nim = ax.imshow(frame_0, vmin=vmin, vmax=vmax, origin=\"upper\", cmap=\"grey\")\ncb = fig.colorbar(im, ax=ax, label=\"γ⁰ (dB)\")\nax.set_title(np.datetime_as_string(subset_db.time.values[0], unit='s'))\nax.set_axis_off()\n\ndef animate(i):\n    frame = subset_db.isel(time=i).values\n    im.set_data(frame)\n    ax.set_title(np.datetime_as_string(subset_db.time.values[i], unit='s'))\n    return (im,)\n\nani = FuncAnimation(fig, animate, frames=subset_db.sizes[\"time\"], interval=300, blit=False)\n\nplt.show()\n\nCreate a javascript animation of the time-series running inline in the notebook:\n\nfrom IPython.display import HTML\n\nHTML(ani.to_jshtml())\n\nSave the animation (animation.gif):\n\nani.save(plot_dir / \"timeseries_animation.gif\", writer=PillowWriter(fps=3))\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-4-create-a-time-series-animation-from-the-db-subset","position":25},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.5. Calculate the Time Series of Means Across the HHHH, frequency A Subset","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-3-5-calculate-the-time-series-of-means-across-the-hhhh-frequency-a-subset","position":26},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.5. Calculate the Time Series of Means Across the HHHH, frequency A Subset","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"To create the time series of means:\n\nCompute subset means for each time-step using data in power scale (\\gamma^o_{pwr}) .\n\nConvert the resulting mean values into dB scale for visualization.\n\nIdentify the axis on which to take the means\n\nNote that the Dataset dimensions are (‘time’, ‘y’, ‘x’)\n\nsubset_pwr.dims\n\nCompute the means in power scale:\n\nSince we want to take the means across the spatial dimensions (dims 1 and 2) on each day, we should pass axis=(1, 2) to np.mean.\n\nThis will compute the backscatter means spatially, while leaving the time dimension in place.\n\nmeans_pwr = np.mean(subset_pwr, axis=(1, 2))\nmeans_pwr\n\nConvert the resulting mean value time-series to dB scale for visualization\n\nmeans_db = 10.*np.log10(means_pwr)\nmeans_db\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-5-calculate-the-time-series-of-means-across-the-hhhh-frequency-a-subset","position":27},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.6. Plot the time series of means","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-3-6-plot-the-time-series-of-means","position":28},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"3.6. Plot the time series of means","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"Plot both the Power and dB time series of means\n\nimport matplotlib.dates as mdates\n\nfig, ax1 = plt.subplots(figsize=(16, 4))\n\n# left y-axis: power\nmeans_pwr.plot.line(ax=ax1, x=\"time\", label=\"power\")\nax1.set_xlabel(\"Date\")\nax1.set_ylabel(r\"$\\overline{\\gamma^o}$ [power]\")\n\n# right y-axis: dB\nax2 = ax1.twinx()\nmeans_db.plot.line(ax=ax2, x='time', color='tab:orange', label='dB')\nax2.set_ylabel(r'$\\overline{\\gamma^o}$ [dB]')\n\nax2.set_xlim(ax1.get_xlim())\nh1, l1 = ax1.get_legend_handles_labels()\nh2, l2 = ax2.get_legend_handles_labels()\nax1.legend(h1 + h2, l1 + l2, loc='upper right')\n\nax1.set_title(r'Time series profile of average band backscatter $\\gamma^o$')\nax2.set_title(\"\")\nplt.tight_layout()\nplt.show()\n\n\n","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-3-6-plot-the-time-series-of-means","position":29},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"5.7. Create Two-Panel Figure, Animating Both the Imagery and the Daily Global Means \\mu_{\\gamma^0_{dB}}","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"type":"lvl3","url":"/notebooks/nisar-gcov-time-series-example#id-5-7-create-two-panel-figure-animating-both-the-imagery-and-the-daily-global-means-mu-gamma-0-db","position":30},{"hierarchy":{"lvl1":"Explore an Example NISAR GCOV Backscatter Time Series","lvl3":"5.7. Create Two-Panel Figure, Animating Both the Imagery and the Daily Global Means \\mu_{\\gamma^0_{dB}}","lvl2":"3. SAR Time Series Visualization, Animation, and Analysis"},"content":"\n\n%%capture\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as an\nimport matplotlib.dates as mdates\n\nt_num = mdates.date2num(subset_db.time.values)                    \nmeans = np.asarray(means_db.compute().values).reshape(-1)\n\nfig = plt.figure(figsize=(12,4))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\n# Image axis\nframe_0 = subset_db.isel(time=0).values\nim = ax1.imshow(frame_0, cmap=\"gray\")\nax1.set_title(np.datetime_as_string(subset_db.time.values[0], unit='D'))\nax1.set_axis_off()\n\n# Line axis\n(l,) = ax2.plot([], [], lw=3)\nax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\nax2.set_xlim(t_num.min(), t_num.max())\n\nax2.set_ylim(np.nanmin(means)-0.5, np.nanmax(means)+0.5)\nax2.set_ylabel(r\"Backscatter Means $\\mu_{\\gamma^0_{dB}}$\")\nax2.set_title(str(subset_db.time.values[0].astype(\"datetime64[D]\")))\n\ndef init():\n    l.set_data([], [])\n    return im, l\n\ndef animate(i):\n    ts = str(subset_db.time.values[i].astype(\"datetime64[D]\"))\n    ax1.set_title(ts)\n    ax2.set_title(ts)\n\n    im.set_data(subset_db.isel(time=i).values)\n    l.set_data(t_num[:i+1], means[:i+1])\n\n    return im, l\n\nani = an.FuncAnimation(fig, animate, frames=len(subset_db.time), init_func=init, interval=400, blit=False)\nplt.tight_layout()\nplt.show()\n\nCreate a javascript animation of the time-series running inline in the notebook:\n\nHTML(ani.to_jshtml())\n\nSave the animated time-series and histogram (animation_histogram.gif):\n\nani.save(plot_dir / 'animation_histogram.gif', writer='pillow', fps=2)\n\nNISAR_GCOV_Time_Series_Example.ipynb - Version 1.0.0 - September 2025\n\nVersion Changes\n\nCreated from \n\nALOS PALSAR example notebook","type":"content","url":"/notebooks/nisar-gcov-time-series-example#id-5-7-create-two-panel-figure-animating-both-the-imagery-and-the-daily-global-means-mu-gamma-0-db","position":31},{"hierarchy":{"lvl1":"Install Required Sorftware"},"type":"lvl1","url":"/notebooks/create-software-environment","position":0},{"hierarchy":{"lvl1":"Install Required Sorftware"},"content":"","type":"content","url":"/notebooks/create-software-environment","position":1},{"hierarchy":{"lvl1":"Set Up an Earthdata Login Account for NISAR Data Access"},"type":"lvl1","url":"/notebooks/set-up-earthdata-login","position":0},{"hierarchy":{"lvl1":"Set Up an Earthdata Login Account for NISAR Data Access"},"content":"","type":"content","url":"/notebooks/set-up-earthdata-login","position":1}]}